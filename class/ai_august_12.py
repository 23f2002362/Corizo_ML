# -*- coding: utf-8 -*-
"""AI August 12.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12MXyVB9PsVCkl_T1eYmHqUSWs8gfqA6w
"""

pip install tensorflow

pip install keras numpy matplotlib mnist

import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf

from tensorflow import keras
import keras
from keras.layers import Dense

from keras.utils import to_categorical

(x_train,y_train),(x_test,y_test)=keras.datasets.mnist.load_data() #mnist -> large datasets of handwritten digits

x_train.shape

x_test.shape

x_train[0].shape

x_train[0]

plt.matshow(x_test[0])

x_test[0]

y_test[0]

x_train=x_train/255
x_test=x_test/255 #scaling

x_test[0]

plt.matshow(x_test[0])

x_train=x_train.reshape(-1,784)
x_test=x_test.reshape(-1,784)

x_train[0]

model=keras.Sequential()
model.add(Dense(64,activation='relu',input_dim=784)) #input layer
model.add(Dense(64,activation='relu')) #hidden layer
model.add(Dense(64,activation='softmax')) #output layer

#dense -> simple layers of neuron
#activation function  -> it will compare the input with the threshold value to activate the particular neuron and to introduce non linearity

model.compile(
    optimizer="adam",
    loss="sparse_categorical_crossentropy",
    metrics=["accuracy"]
)

#optimizer -> to adjust the model weights to maximize the loss function
#performance metrics -> performance score
#loss -> how well our algo is performing

model.fit(x_train,y_train,epochs=5)
#epochs ->  training our neural network with the training data in one cycle -> one forward pass and backward pass

model.evaluate(x_test,y_test)

ans=model.predict(x_test)
ans

output=np.argmax(ans[0])
print(output)

